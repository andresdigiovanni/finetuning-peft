{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32f6eb",
   "metadata": {},
   "source": [
    "# 1. Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99498a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53faef66",
   "metadata": {},
   "source": [
    "# 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Normalize and tokenize by removing punctuation and stopwords.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in STOP_WORDS]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_by_label(df, label, top_n=20):\n",
    "    \"\"\"Returns the most frequent words in a sentiment class.\"\"\"\n",
    "    sentences = df[df[\"sentiment\"] == label][\"sentence\"]\n",
    "    words = [\n",
    "        word.lower()\n",
    "        for sentence in sentences\n",
    "        for word in word_tokenize(sentence)\n",
    "        if word.isalpha() and word.lower() not in STOP_WORDS\n",
    "    ]\n",
    "    most_common = Counter(words).most_common(top_n)\n",
    "    return pd.DataFrame(most_common, columns=[\"word\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred, y_prob):\n",
    "    y_bin = label_binarize(y_true, classes=np.unique(y_true))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob, multi_class=\"ovr\"),\n",
    "        \"avg_precision\": average_precision_score(y_bin, y_prob, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66410551",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c37811",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/FinancialPhraseBank-v1.0/Sentences_75Agree.txt\"\n",
    "with open(file_path, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "    lines = [line.strip() for line in file if \"@\" in line]\n",
    "\n",
    "data = [line.rsplit(\"@\", 1) for line in lines]\n",
    "df_raw = pd.DataFrame(data, columns=[\"sentence\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total examples: {len(df_raw)}\")\n",
    "print(\"\\nClass distribution:\\n\", df_raw[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5128f",
   "metadata": {},
   "source": [
    "# 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dbc804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning\n",
    "df_raw[\"clean_text\"] = df_raw[\"sentence\"].apply(clean_text)\n",
    "\n",
    "# Assign numeric labels\n",
    "df_raw[\"label\"] = df_raw[\"sentiment\"].map(LABEL_TO_ID)\n",
    "\n",
    "# Train-eval split\n",
    "train_df, eval_df = train_test_split(\n",
    "    df_raw, test_size=0.2, stratify=df_raw[\"label\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac76a66",
   "metadata": {},
   "source": [
    "# 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64fc12",
   "metadata": {},
   "source": [
    "## 5.1. Model 1: TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5569c6a",
   "metadata": {},
   "source": [
    "##### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"clean_text\"]\n",
    "X_eval = eval_df[\"clean_text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "y_eval = eval_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0ae8b",
   "metadata": {},
   "source": [
    "##### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cedfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10_000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_eval_vec = vectorizer.transform(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e84a35",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e2, log=True),\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"]),\n",
    "        \"max_iter\": 1_000,\n",
    "        \"multi_class\": \"ovr\",\n",
    "    }\n",
    "\n",
    "    # Some combinations are invalid\n",
    "    if params[\"penalty\"] == \"l1\" and params[\"solver\"] == \"saga\":\n",
    "        pass  # v√°lido\n",
    "    elif params[\"penalty\"] == \"l1\" and params[\"solver\"] != \"liblinear\":\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    model = OneVsRestClassifier(LogisticRegression(**params))\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        preds = cross_val_predict(\n",
    "            model, X_train_vec, y_train, cv=skf, method=\"predict_proba\"\n",
    "        )\n",
    "\n",
    "    roc = roc_auc_score(y_train, preds, multi_class=\"ovr\")\n",
    "    return roc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458555b8",
   "metadata": {},
   "source": [
    "##### Training best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d82e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_params[\"max_iter\"] = 1_000\n",
    "best_params[\"multi_class\"] = \"ovr\"\n",
    "\n",
    "logreg = OneVsRestClassifier(LogisticRegression(**best_params))\n",
    "logreg.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead8f428",
   "metadata": {},
   "source": [
    "##### Run predictions on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_eval_vec)\n",
    "y_prob = logreg.predict_proba(X_eval_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81352a7f",
   "metadata": {},
   "source": [
    "##### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd86c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_metrics = classification_metrics(y_eval, y_pred, y_prob)\n",
    "df_logreg_metrics = pd.DataFrame.from_dict(\n",
    "    logreg_metrics, orient=\"index\", columns=[\"scores\"]\n",
    ")\n",
    "print(df_logreg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da8779",
   "metadata": {},
   "source": [
    "## 5.2. Model 2: TF-IDF + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160cb779",
   "metadata": {},
   "source": [
    "##### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ba508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"clean_text\"]\n",
    "X_eval = eval_df[\"clean_text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "y_eval = eval_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bc419",
   "metadata": {},
   "source": [
    "##### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10_000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_eval_vec = vectorizer.transform(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce21cc",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    preds = cross_val_predict(\n",
    "        model, X_train_vec, y_train, cv=skf, method=\"predict_proba\"\n",
    "    )\n",
    "    roc = roc_auc_score(y_train, preds, multi_class=\"ovr\")\n",
    "    return roc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54a08f",
   "metadata": {},
   "source": [
    "##### Training best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9765cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_params[\"eval_metric\"] = \"mlogloss\"\n",
    "\n",
    "xgb = XGBClassifier(**best_params)\n",
    "xgb.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99ffee",
   "metadata": {},
   "source": [
    "##### Run predictions on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c35c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_eval_vec)\n",
    "y_prob = xgb.predict_proba(X_eval_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99df88",
   "metadata": {},
   "source": [
    "##### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics = classification_metrics(y_eval, y_pred, y_prob)\n",
    "df_xgb_metrics = pd.DataFrame.from_dict(xgb_metrics, orient=\"index\", columns=[\"scores\"])\n",
    "print(df_xgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0bea64",
   "metadata": {},
   "source": [
    "## 5.3. Model 3: Zero-shot with LLM (HuggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62f93a",
   "metadata": {},
   "source": [
    "##### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3845437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"]\n",
    "X_eval = eval_df[\"sentence\"]\n",
    "y_train = train_df[\"label\"]\n",
    "y_eval = eval_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188bd46",
   "metadata": {},
   "source": [
    "##### Load a pre-trained transformer for zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "zero_shot_classifier = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True,\n",
    "    device=device,\n",
    "    task=\"zero-shot-classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a977a1e",
   "metadata": {},
   "source": [
    "##### Run zero-shot classification on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed618f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = X_eval.tolist()\n",
    "batch_size = 32\n",
    "\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    batch = sentences[i : i + batch_size]\n",
    "    outputs = zero_shot_classifier(batch)\n",
    "\n",
    "    for probs in outputs:\n",
    "        scores = [s[\"score\"] for s in probs]\n",
    "        y_prob.append(scores)\n",
    "        y_pred.append(int(np.argmax(scores)))\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba6622",
   "metadata": {},
   "source": [
    "##### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e71c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_metrics = classification_metrics(y_eval, y_pred, y_prob)\n",
    "df_zero_shot_metrics = pd.DataFrame.from_dict(\n",
    "    zero_shot_metrics, orient=\"index\", columns=[\"scores\"]\n",
    ")\n",
    "print(df_zero_shot_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c018b6",
   "metadata": {},
   "source": [
    "## 5.4. Model 4: Fine-tuned LLM using PEFT + LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413441a",
   "metadata": {},
   "source": [
    "##### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb74d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"]\n",
    "X_eval = eval_df[\"sentence\"]\n",
    "y_train = train_df[\"label\"]\n",
    "y_eval = eval_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b509a",
   "metadata": {},
   "source": [
    "##### Load tokenizer and base model for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e53af",
   "metadata": {},
   "source": [
    "##### Split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1668bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\"text\": X_train, \"label\": y_train})\n",
    "dataset = Dataset.from_pandas(df_train)\n",
    "\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "tokenized = tokenized.train_test_split(test_size=0.1)\n",
    "train_ds = tokenized[\"train\"]\n",
    "eval_ds = tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd86e4",
   "metadata": {},
   "source": [
    "##### Prepare model for parameter-efficient fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44851f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=3\n",
    ")\n",
    "base_model.gradient_checkpointing_enable()\n",
    "base_model = prepare_model_for_kbit_training(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca427892",
   "metadata": {},
   "source": [
    "##### Define LoRA configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "peft_model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf730e",
   "metadata": {},
   "source": [
    "##### Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_model\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    # fp16=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19f9da",
   "metadata": {},
   "source": [
    "##### Define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53faa566",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77056144",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd9430",
   "metadata": {},
   "source": [
    "##### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0566fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually tokenize the evaluation set\n",
    "eval_encodings = tokenizer(\n",
    "    list(X_eval), truncation=True, padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Move tensors to the same device as the model\n",
    "eval_encodings = {k: v.to(model.device) for k, v in eval_encodings.items()}\n",
    "\n",
    "model = trainer.model\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    outputs = model(**eval_encodings)\n",
    "    logits = outputs.logits\n",
    "    y_prob = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()\n",
    "    y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6121fd32",
   "metadata": {},
   "source": [
    "##### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_metrics = classification_metrics(y_eval, y_pred, y_prob)\n",
    "df_fine_tuning_metrics = pd.DataFrame.from_dict(\n",
    "    fine_tuning_metrics, orient=\"index\", columns=[\"scores\"]\n",
    ")\n",
    "print(df_fine_tuning_metrics.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fdbe0",
   "metadata": {},
   "source": [
    "##### Misclassified Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0cdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_eval.reset_index(drop=True)\n",
    "y_pred_labels = y_pred\n",
    "\n",
    "df_errors = pd.DataFrame(\n",
    "    {\n",
    "        \"Text\": X_eval.reset_index(drop=True),\n",
    "        \"True Label\": y_true,\n",
    "        \"Predicted Label\": y_pred_labels,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_misclassified = df_errors[df_errors[\"True Label\"] != df_errors[\"Predicted Label\"]]\n",
    "sample_errors = df_misclassified.sample(3, random_state=42)\n",
    "\n",
    "explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "\n",
    "for i, (_, row) in enumerate(sample_errors.iterrows()):\n",
    "    print(\"=\" * 20, f\"Example {i + 1}\", \"=\" * 20)\n",
    "    print(f\"Text:\\n{row['Text']}\\n\")\n",
    "    print(f\"True Label: {row['True Label']}\")\n",
    "    print(f\"Predicted Label: {row['Predicted Label']}\")\n",
    "    word_attributions = explainer(row[\"Text\"])\n",
    "    explainer.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90c9b6",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(metrics_dict):\n",
    "    df_compare = pd.DataFrame(metrics_dict).T\n",
    "    df_compare = df_compare[\n",
    "        [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"avg_precision\"]\n",
    "    ]\n",
    "    df_compare.index.name = \"Model\"\n",
    "    return df_compare\n",
    "\n",
    "\n",
    "metrics_dict = {\n",
    "    \"TF-IDF + Logistic Regression\": logreg_metrics,\n",
    "    \"TF-IDF + XGBoost\": xgb_metrics,\n",
    "    \"Zero-shot LLM\": zero_shot_metrics,\n",
    "    \"Fine-tuned LLM\": fine_tuning_metrics,\n",
    "}\n",
    "\n",
    "df_compare = compare_models(metrics_dict)\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.T.plot(kind=\"bar\", figsize=(8, 5))\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(title=\"Model\", loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning-peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
